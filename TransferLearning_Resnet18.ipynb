{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INN54zXpTcZw"
      },
      "source": [
        "## Exercise 3: Transfer Learning (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgDHswfp0k7m"
      },
      "source": [
        "In practice, people won't train an entire CNN from scratch, because it is relatively rare to have a dataset of sufficient size (or sufficient computational power). Instead, it is common to pretrain a CNN on a very large dataset and then use the CNN either as an initialization or a fixed feature extractor for the task of interest.\n",
        "\n",
        "In this task, you will learn how to use a pretrained CNN for CIFAR-10 classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f21CjwoW8ty5"
      },
      "source": [
        "### Task1: Load pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ-21Pv183TX"
      },
      "source": [
        "`torchvision.models` (https://pytorch.org/vision/stable/models.html) contains definitions of models for addressing different tasks, including: image classification, pixelwise semantic segmentation, object detection, instance segmentation, person keypoint detection and video classification.\n",
        "\n",
        "First, you should load the **pretrained** ResNet-18 that has already been trained on [ImageNet](https://www.image-net.org/) using `torchvision.models`. If you are interested in more details about Resnet-18, read this paper https://arxiv.org/pdf/1512.03385.pdf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaHP0VfAVuDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b42c59-7f40-4cc1-ca5b-1b1692e2b2fb"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "print(resnet18)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQkZUZH84q8"
      },
      "source": [
        "### Task2: Create data loaders for CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTlRo-CJ4GQD"
      },
      "source": [
        "Then you need to create a dataloader of CIFAR-10. Note that the model you load has been trained on **ImageNet** and it expects inputs as mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be **at least** 224. So you need to preprocess the CIFAR-10 data to make sure it has a height and width. See [`torchvision.transforms.Resize`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Resize).\n",
        "You will probably want to add this transform appropriately to the `transform` you created in a previous task.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhFys7OQV1Wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f73712-f9db-4f66-e805-2473611b1e31"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "batch_size = 100\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                            torchvision.transforms.Resize((224, 224))])\n",
        "\n",
        "test_cifar10_dataset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform)\n",
        "train_cifar10_dataset = torchvision.datasets.CIFAR10('./data', train=True, transform=transform)\n",
        "test_cifar10_loader = torch.utils.data.DataLoader(test_cifar10_dataset, batch_size=batch_size, shuffle=False)\n",
        "train_cifar10_loader = torch.utils.data.DataLoader(train_cifar10_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8nR_aBi9Atb"
      },
      "source": [
        "### Task3: Classify test data on pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8IXXu-J9grR"
      },
      "source": [
        "Use the model you load to classify the **test** CIFAR-10 data and print out the test accuracy.\n",
        "\n",
        "Don't be surprised if the accuracy is bad!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOuCodyJ4FYp"
      },
      "source": [
        "def test():  \n",
        "  resnet18.to(device)\n",
        "  resnet18.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    tot = 0\n",
        "    for images, labels in test_cifar10_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = resnet18(images)\n",
        "      prediction = outputs.data.max(1, keepdim=True)[1]\n",
        "      correct += prediction.eq(labels.data.view_as(prediction)).sum()\n",
        "      tot += len(images)\n",
        "      print(f'Accuracy: {correct/tot}')\n",
        "\n",
        "  print(f'Test Accuracy: {100.*correct/len(test_cifar10_dataset)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOMWjCAgNnGn",
        "outputId": "817473b1-86b2-487a-cf50-892d3c12d7ae"
      },
      "source": [
        "# Testing pretrained Resnet18 model on CIFAR10 dataset\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0\n",
            "Accuracy: 0.0005000000237487257\n",
            "Accuracy: 0.0004761904710903764\n",
            "Accuracy: 0.00045454545761458576\n",
            "Accuracy: 0.00043478261795826256\n",
            "Accuracy: 0.00041666667675599456\n",
            "Accuracy: 0.00039999998989515007\n",
            "Accuracy: 0.0003846153849735856\n",
            "Accuracy: 0.000370370369637385\n",
            "Accuracy: 0.0003571428533177823\n",
            "Accuracy: 0.00034482759656384587\n",
            "Accuracy: 0.00033333332976326346\n",
            "Accuracy: 0.0003225806576665491\n",
            "Accuracy: 0.0003124999930150807\n",
            "Accuracy: 0.0003030303050763905\n",
            "Accuracy: 0.00029411763534881175\n",
            "Accuracy: 0.0002857142826542258\n",
            "Accuracy: 0.00027777778450399637\n",
            "Accuracy: 0.0002702702768146992\n",
            "Accuracy: 0.0002631578827276826\n",
            "Accuracy: 0.00025641024694778025\n",
            "Accuracy: 0.0002500000118743628\n",
            "Accuracy: 0.0002439024392515421\n",
            "Accuracy: 0.0002380952355451882\n",
            "Accuracy: 0.00023255814448930323\n",
            "Accuracy: 0.00022727272880729288\n",
            "Accuracy: 0.00022222222469281405\n",
            "Accuracy: 0.00021739130897913128\n",
            "Accuracy: 0.00021276595361996442\n",
            "Accuracy: 0.00020833333837799728\n",
            "Accuracy: 0.0002040816325461492\n",
            "Accuracy: 0.00019999999494757503\n",
            "Accuracy: 0.0001960784284165129\n",
            "Accuracy: 0.0001923076924867928\n",
            "Accuracy: 0.00018867924518417567\n",
            "Accuracy: 0.000370370369637385\n",
            "Accuracy: 0.0003636363544501364\n",
            "Accuracy: 0.0003571428533177823\n",
            "Accuracy: 0.0003508772060740739\n",
            "Accuracy: 0.00034482759656384587\n",
            "Accuracy: 0.000338983052643016\n",
            "Accuracy: 0.00033333332976326346\n",
            "Accuracy: 0.00032786885276436806\n",
            "Accuracy: 0.0003225806576665491\n",
            "Accuracy: 0.0003174603043589741\n",
            "Accuracy: 0.0003124999930150807\n",
            "Accuracy: 0.0003076923021581024\n",
            "Accuracy: 0.0003030303050763905\n",
            "Accuracy: 0.00029850745340809226\n",
            "Accuracy: 0.00029411763534881175\n",
            "Accuracy: 0.00028985505923628807\n",
            "Accuracy: 0.0002857142826542258\n",
            "Accuracy: 0.00028169015422463417\n",
            "Accuracy: 0.00027777778450399637\n",
            "Accuracy: 0.0002739726041909307\n",
            "Accuracy: 0.0002702702768146992\n",
            "Accuracy: 0.00026666666963137686\n",
            "Accuracy: 0.0002631578827276826\n",
            "Accuracy: 0.0002597402490209788\n",
            "Accuracy: 0.00025641024694778025\n",
            "Accuracy: 0.00025316455867141485\n",
            "Accuracy: 0.0002500000118743628\n",
            "Accuracy: 0.0002469135797582567\n",
            "Accuracy: 0.0002439024392515421\n",
            "Accuracy: 0.00024096385459415615\n",
            "Accuracy: 0.0002380952355451882\n",
            "Accuracy: 0.00023529412283096462\n",
            "Accuracy: 0.00023255814448930323\n",
            "Accuracy: 0.00022988505952525884\n",
            "Accuracy: 0.00022727272880729288\n",
            "Accuracy: 0.00022471910051535815\n",
            "Accuracy: 0.00022222222469281405\n",
            "Accuracy: 0.00021978022414259613\n",
            "Accuracy: 0.00021739130897913128\n",
            "Accuracy: 0.00021505376207642257\n",
            "Accuracy: 0.00021276595361996442\n",
            "Accuracy: 0.00021052631200291216\n",
            "Accuracy: 0.00020833333837799728\n",
            "Accuracy: 0.0002061855630017817\n",
            "Accuracy: 0.0002040816325461492\n",
            "Accuracy: 0.0003030303050763905\n",
            "Accuracy: 0.00029999998514540493\n",
            "Test Accuracy: 0.029999999329447746%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETLezHR0-ByE"
      },
      "source": [
        "### Task 4: Update model for CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbQrsL-U-Faq"
      },
      "source": [
        "Now try to improve the test accuracy. We offer several possible solutions:\n",
        "\n",
        "(1) You can try to directly continue to train the model you load with the CIFAR-10 training data. \n",
        "\n",
        "(2) For efficiency, you can try to freeze part of the parameters of the loaded models. For example, you can first freeze all parameters by\n",
        "\n",
        "```\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "```\n",
        "and then unfreeze the last few layers by setting `somelayer.requires_grad=True`.\n",
        "\n",
        "You are also welcome to try any other approach you can think of.\n",
        "\n",
        "\n",
        "**Note:** You should print out the test accuracy and to get full credits, the test accuracy should be at least **80%**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2H2oDDyWv8t"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "\n",
        "cnt = 0\n",
        "for child in resnet18.children():\n",
        "  cnt += 1\n",
        "  if cnt < 7:\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "optimizer = optim.SGD(list(filter(lambda p: p.requires_grad, resnet18.parameters())), lr=0.01, momentum=0.9)\n",
        "\n",
        "def train(epoch):\n",
        "  resnet18.to(device)\n",
        "  resnet18.train()\n",
        "\n",
        "  for batch_idx, (images, targets) in enumerate(train_cifar10_loader):\n",
        "    images = images.to(device)\n",
        "    targets = targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = resnet18(images)\n",
        "    loss = F.cross_entropy(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx%10 == 0:\n",
        "      print(f'EPOCH: {epoch} [{batch_idx*len(images)}/{len(train_cifar10_dataset)}] Loss: {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q331sZZ6uk0_",
        "outputId": "a89359d5-50c2-475e-ea56-c4edc75650d9"
      },
      "source": [
        "# Train Resnet for 1 epoch using CIFAR-10 Dataset\n",
        "train(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1 [0/50000] Loss: 0.660830020904541\n",
            "EPOCH: 1 [1000/50000] Loss: 0.5830726027488708\n",
            "EPOCH: 1 [2000/50000] Loss: 0.5147011876106262\n",
            "EPOCH: 1 [3000/50000] Loss: 0.5107433795928955\n",
            "EPOCH: 1 [4000/50000] Loss: 0.478744238615036\n",
            "EPOCH: 1 [5000/50000] Loss: 0.39798057079315186\n",
            "EPOCH: 1 [6000/50000] Loss: 0.31346216797828674\n",
            "EPOCH: 1 [7000/50000] Loss: 0.25302502512931824\n",
            "EPOCH: 1 [8000/50000] Loss: 0.39963868260383606\n",
            "EPOCH: 1 [9000/50000] Loss: 0.4802074730396271\n",
            "EPOCH: 1 [10000/50000] Loss: 0.23381084203720093\n",
            "EPOCH: 1 [11000/50000] Loss: 0.41112786531448364\n",
            "EPOCH: 1 [12000/50000] Loss: 0.30601832270622253\n",
            "EPOCH: 1 [13000/50000] Loss: 0.24655316770076752\n",
            "EPOCH: 1 [14000/50000] Loss: 0.39226046204566956\n",
            "EPOCH: 1 [15000/50000] Loss: 0.29811060428619385\n",
            "EPOCH: 1 [16000/50000] Loss: 0.2812885046005249\n",
            "EPOCH: 1 [17000/50000] Loss: 0.3019710183143616\n",
            "EPOCH: 1 [18000/50000] Loss: 0.23746557533740997\n",
            "EPOCH: 1 [19000/50000] Loss: 0.43034327030181885\n",
            "EPOCH: 1 [20000/50000] Loss: 0.30074137449264526\n",
            "EPOCH: 1 [21000/50000] Loss: 0.31446582078933716\n",
            "EPOCH: 1 [22000/50000] Loss: 0.3262994885444641\n",
            "EPOCH: 1 [23000/50000] Loss: 0.2408715784549713\n",
            "EPOCH: 1 [24000/50000] Loss: 0.35134586691856384\n",
            "EPOCH: 1 [25000/50000] Loss: 0.4383227825164795\n",
            "EPOCH: 1 [26000/50000] Loss: 0.18349409103393555\n",
            "EPOCH: 1 [27000/50000] Loss: 0.4398854970932007\n",
            "EPOCH: 1 [28000/50000] Loss: 0.36743953824043274\n",
            "EPOCH: 1 [29000/50000] Loss: 0.1262795627117157\n",
            "EPOCH: 1 [30000/50000] Loss: 0.3719150424003601\n",
            "EPOCH: 1 [31000/50000] Loss: 0.35178130865097046\n",
            "EPOCH: 1 [32000/50000] Loss: 0.30413568019866943\n",
            "EPOCH: 1 [33000/50000] Loss: 0.3001580834388733\n",
            "EPOCH: 1 [34000/50000] Loss: 0.1370212286710739\n",
            "EPOCH: 1 [35000/50000] Loss: 0.27087604999542236\n",
            "EPOCH: 1 [36000/50000] Loss: 0.17951804399490356\n",
            "EPOCH: 1 [37000/50000] Loss: 0.30613064765930176\n",
            "EPOCH: 1 [38000/50000] Loss: 0.41491013765335083\n",
            "EPOCH: 1 [39000/50000] Loss: 0.2576860785484314\n",
            "EPOCH: 1 [40000/50000] Loss: 0.1961609274148941\n",
            "EPOCH: 1 [41000/50000] Loss: 0.1914629340171814\n",
            "EPOCH: 1 [42000/50000] Loss: 0.3264504373073578\n",
            "EPOCH: 1 [43000/50000] Loss: 0.2125169336795807\n",
            "EPOCH: 1 [44000/50000] Loss: 0.21859733760356903\n",
            "EPOCH: 1 [45000/50000] Loss: 0.31895911693573\n",
            "EPOCH: 1 [46000/50000] Loss: 0.26608145236968994\n",
            "EPOCH: 1 [47000/50000] Loss: 0.17394578456878662\n",
            "EPOCH: 1 [48000/50000] Loss: 0.313383549451828\n",
            "EPOCH: 1 [49000/50000] Loss: 0.3407275676727295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49DRx5O-xTPl",
        "outputId": "91f1d247-340f-4102-efd8-9e79ca879cde"
      },
      "source": [
        "# Test RESNET18 Model on CIFAR-10 Dataset after training\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9199999570846558\n",
            "Accuracy: 0.9149999618530273\n",
            "Accuracy: 0.9100000262260437\n",
            "Accuracy: 0.9074999690055847\n",
            "Accuracy: 0.9000000357627869\n",
            "Accuracy: 0.9100000262260437\n",
            "Accuracy: 0.9142857193946838\n",
            "Accuracy: 0.9112499952316284\n",
            "Accuracy: 0.9100000262260437\n",
            "Accuracy: 0.9130000472068787\n",
            "Accuracy: 0.9154545664787292\n",
            "Accuracy: 0.9183333516120911\n",
            "Accuracy: 0.9169231057167053\n",
            "Accuracy: 0.9178571105003357\n",
            "Accuracy: 0.9160000085830688\n",
            "Accuracy: 0.9181249737739563\n",
            "Accuracy: 0.9182352423667908\n",
            "Accuracy: 0.9166666865348816\n",
            "Accuracy: 0.9157894253730774\n",
            "Accuracy: 0.9160000681877136\n",
            "Accuracy: 0.9142857193946838\n",
            "Accuracy: 0.9127272963523865\n",
            "Accuracy: 0.9095652103424072\n",
            "Accuracy: 0.909583330154419\n",
            "Accuracy: 0.9107999801635742\n",
            "Accuracy: 0.9084615111351013\n",
            "Accuracy: 0.9096296429634094\n",
            "Accuracy: 0.9092857241630554\n",
            "Accuracy: 0.9093104004859924\n",
            "Accuracy: 0.909333348274231\n",
            "Accuracy: 0.9090322852134705\n",
            "Accuracy: 0.9096874594688416\n",
            "Accuracy: 0.9115151762962341\n",
            "Accuracy: 0.9097058176994324\n",
            "Accuracy: 0.9091428518295288\n",
            "Accuracy: 0.9094444513320923\n",
            "Accuracy: 0.9105405807495117\n",
            "Accuracy: 0.907631516456604\n",
            "Accuracy: 0.9079486727714539\n",
            "Accuracy: 0.9082500338554382\n",
            "Accuracy: 0.9087805151939392\n",
            "Accuracy: 0.9090476036071777\n",
            "Accuracy: 0.9090697765350342\n",
            "Accuracy: 0.9100000262260437\n",
            "Accuracy: 0.9102222323417664\n",
            "Accuracy: 0.9102174043655396\n",
            "Accuracy: 0.9110637903213501\n",
            "Accuracy: 0.9097917079925537\n",
            "Accuracy: 0.9095918536186218\n",
            "Accuracy: 0.9089999794960022\n",
            "Accuracy: 0.9094117283821106\n",
            "Accuracy: 0.9092307686805725\n",
            "Accuracy: 0.9090566039085388\n",
            "Accuracy: 0.909074068069458\n",
            "Accuracy: 0.9089090824127197\n",
            "Accuracy: 0.9092857241630554\n",
            "Accuracy: 0.9089474081993103\n",
            "Accuracy: 0.9091379642486572\n",
            "Accuracy: 0.9086440801620483\n",
            "Accuracy: 0.9085000157356262\n",
            "Accuracy: 0.9086885452270508\n",
            "Accuracy: 0.9088709950447083\n",
            "Accuracy: 0.9085713624954224\n",
            "Accuracy: 0.9087499976158142\n",
            "Accuracy: 0.9087691903114319\n",
            "Accuracy: 0.9092424511909485\n",
            "Accuracy: 0.9098507165908813\n",
            "Accuracy: 0.909852921962738\n",
            "Accuracy: 0.9099999666213989\n",
            "Accuracy: 0.9101428389549255\n",
            "Accuracy: 0.9097183346748352\n",
            "Accuracy: 0.909861147403717\n",
            "Accuracy: 0.9097260236740112\n",
            "Accuracy: 0.9104054570198059\n",
            "Accuracy: 0.9101333618164062\n",
            "Accuracy: 0.9099999666213989\n",
            "Accuracy: 0.9097402095794678\n",
            "Accuracy: 0.9098717570304871\n",
            "Accuracy: 0.9097468256950378\n",
            "Accuracy: 0.9101250171661377\n",
            "Accuracy: 0.9106172919273376\n",
            "Accuracy: 0.9102439284324646\n",
            "Accuracy: 0.9098795056343079\n",
            "Accuracy: 0.9103571176528931\n",
            "Accuracy: 0.909529447555542\n",
            "Accuracy: 0.9096511602401733\n",
            "Accuracy: 0.909885048866272\n",
            "Accuracy: 0.9101136326789856\n",
            "Accuracy: 0.9103370904922485\n",
            "Accuracy: 0.9103333353996277\n",
            "Accuracy: 0.9106593728065491\n",
            "Accuracy: 0.9109782576560974\n",
            "Accuracy: 0.9103225469589233\n",
            "Accuracy: 0.9098935723304749\n",
            "Accuracy: 0.9095789194107056\n",
            "Accuracy: 0.909583330154419\n",
            "Accuracy: 0.9096906781196594\n",
            "Accuracy: 0.9095918536186218\n",
            "Accuracy: 0.9090909361839294\n",
            "Accuracy: 0.909500002861023\n",
            "Test Accuracy: 90.94999694824219%\n"
          ]
        }
      ]
    }
  ]
}